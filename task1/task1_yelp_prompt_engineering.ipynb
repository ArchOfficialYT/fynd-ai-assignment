{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b20f96",
   "metadata": {},
   "source": [
    "# Task 1: Yelp Rating Prediction via Prompt Engineering\n",
    "\n",
    "This notebook explores how different prompt designs affect an LLM’s ability\n",
    "to predict Yelp star ratings (1–5) from review text.\n",
    "\n",
    "We evaluate:\n",
    "- Accuracy\n",
    "- JSON validity\n",
    "- Reliability across prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2beee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dfca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"yelp.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a94eb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id',\n",
       "       'cool', 'useful', 'funny'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75077f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  My wife took me here on my birthday for breakf...      5\n",
       "1  I have no idea why some people give bad review...      5\n",
       "2  love the gyro plate. Rice is so good and I als...      4\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'stars']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c04bb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  We got here around midnight last Friday... the...      4\n",
       "1  Brought a friend from Louisiana here.  She say...      5\n",
       "2  Every friday, my dad and I eat here. We order ...      3\n",
       "3  My husband and I were really, really disappoin...      1\n",
       "4  Love this place!  Was in phoenix 3 weeks for w...      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(200, random_state=42)\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "sample_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a2715",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We use a sampled subset of 200 Yelp reviews for efficiency.\n",
    "Only the review text and corresponding star ratings are retained,\n",
    "as these are sufficient for the rating prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-flash-lite-latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5316d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v1(review_text):\n",
    "    return f\"\"\"\n",
    "You are a JSON generator.\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "Do NOT add explanations outside JSON.\n",
    "Do NOT use markdown.\n",
    "Do NOT add any text before or after JSON.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\n",
    "JSON output:\n",
    "{{\n",
    "  \"predicted_stars\": 1-5,\n",
    "  \"explanation\": \"short reason\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retry logic to handle temporary API quota exhaustion during batch evaluation\n",
    "\n",
    "def safe_generate(prompt, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return model.generate_content(prompt)\n",
    "        except ResourceExhausted:\n",
    "            wait_time = 20 + attempt * 10 + random.uniform(0, 5)\n",
    "            print(f\"Quota hit. Waiting {wait_time:.1f}s...\")\n",
    "            time.sleep(wait_time)\n",
    "    raise RuntimeError(\"Failed due to repeated quota exhaustion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88edb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_response(response_text):\n",
    "    try:\n",
    "        json_str = re.search(r\"\\{.*\\}\", response_text, re.DOTALL).group()\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        predicted = int(float(data[\"predicted_stars\"]))\n",
    "        return predicted, True\n",
    "    except Exception:\n",
    "        return None, False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:49<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_v1 = []\n",
    "\n",
    "for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    review = row[\"text\"]\n",
    "    actual = row[\"stars\"]\n",
    "\n",
    "    try:\n",
    "        response = safe_generate(prompt_v1(review))\n",
    "        predicted, valid = parse_response(response.text)\n",
    "    except Exception:\n",
    "        predicted, valid = None, False\n",
    "\n",
    "    results_v1.append({\n",
    "        \"actual\": actual,\n",
    "        \"predicted\": predicted,\n",
    "        \"json_valid\": valid\n",
    "    })\n",
    "\n",
    "    time.sleep(0.4)  # prevents quota exhaustion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121ad6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>json_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted  json_valid\n",
       "0       4        4.0        True\n",
       "1       5        5.0        True\n",
       "2       3        4.0        True\n",
       "3       1        1.0        True\n",
       "4       5        5.0        True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_v1 = pd.DataFrame(results_v1)\n",
    "results_df_v1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbeb2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.065), np.float64(0.095))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v1 = (results_df_v1[\"actual\"] == results_df_v1[\"predicted\"]).mean()\n",
    "json_valid_rate_v1 = results_df_v1[\"json_valid\"].mean()\n",
    "\n",
    "accuracy_v1, json_valid_rate_v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.065), np.float64(0.095))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exact_accuracy_v1 = accuracy_v1\n",
    "\n",
    "within_one_accuracy_v1 = (\n",
    "    (results_df_v1[\"actual\"] - results_df_v1[\"predicted\"]).abs() <= 1\n",
    ").mean()\n",
    "\n",
    "exact_accuracy_v1, within_one_accuracy_v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e092a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_v1 = results_df_v1[\n",
    "    (results_df_v1[\"json_valid\"] == True) &\n",
    "    (results_df_v1[\"predicted\"].notna())\n",
    "]\n",
    "\n",
    "len(valid_df_v1), len(results_df_v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6842105263157895), np.float64(1.0), np.float64(0.095))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_accuracy_v1 = (\n",
    "    valid_df_v1[\"actual\"] == valid_df_v1[\"predicted\"]\n",
    ").mean()\n",
    "\n",
    "within_one_accuracy_v1 = (\n",
    "    (valid_df_v1[\"actual\"] - valid_df_v1[\"predicted\"]).abs() <= 1\n",
    ").mean()\n",
    "\n",
    "json_valid_rate_v1 = results_df_v1[\"json_valid\"].mean()\n",
    "\n",
    "exact_accuracy_v1, within_one_accuracy_v1, json_valid_rate_v1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2204537",
   "metadata": {},
   "source": [
    "### Prompt Version 1 — Baseline Results\n",
    "\n",
    "- Exact Match Accuracy (valid outputs only): **{exact_accuracy_v1:.2%}**\n",
    "- Within ±1 Star Accuracy (valid outputs only): **{within_one_accuracy_v1:.2%}**\n",
    "- JSON Validity Rate (overall): **{json_valid_rate_v1:.2%}**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cad2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v2(review_text):\n",
    "    return f\"\"\"\n",
    "You are a rating classifier.\n",
    "\n",
    "Your task:\n",
    "- Analyze the sentiment of the review.\n",
    "- Map sentiment to star ratings using the rules below.\n",
    "\n",
    "Rules:\n",
    "- Very negative experience → 1 star\n",
    "- Mostly negative with few positives → 2 stars\n",
    "- Mixed or average experience → 3 stars\n",
    "- Mostly positive with minor issues → 4 stars\n",
    "- Extremely positive, no complaints → 5 stars\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "No markdown. No extra text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\n",
    "JSON output:\n",
    "{{\n",
    "  \"predicted_stars\": 1-5,\n",
    "  \"explanation\": \"short justification\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa838549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:20<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_v2 = []\n",
    "\n",
    "for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    review = row[\"text\"]\n",
    "    actual = row[\"stars\"]\n",
    "\n",
    "    try:\n",
    "        response = safe_generate(prompt_v2(review))\n",
    "        predicted, valid = parse_response(response.text)\n",
    "    except Exception:\n",
    "        predicted, valid = None, False\n",
    "\n",
    "    results_v2.append({\n",
    "        \"actual\": actual,\n",
    "        \"predicted\": predicted,\n",
    "        \"json_valid\": valid\n",
    "    })\n",
    "\n",
    "    time.sleep(0.4)  # prevent quota exhaustion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43175f64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results_df_v2 = pd.DataFrame(\u001b[43mresults_v2\u001b[49m)\n\u001b[32m      2\u001b[39m results_df_v2.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'results_v2' is not defined"
     ]
    }
   ],
   "source": [
    "results_df_v2 = pd.DataFrame(results_v2)\n",
    "results_df_v2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89914625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float64(0.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v2 = (results_df_v2[\"actual\"] == results_df_v2[\"predicted\"]).mean()\n",
    "json_valid_rate_v2 = results_df_v2[\"json_valid\"].mean()\n",
    "\n",
    "accuracy_v2, json_valid_rate_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48394439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_v2 = results_df_v2[\n",
    "    (results_df_v2[\"json_valid\"] == True) &\n",
    "    (results_df_v2[\"predicted\"].notna())\n",
    "]\n",
    "\n",
    "exact_accuracy_v2 = (\n",
    "    valid_df_v2[\"actual\"] == valid_df_v2[\"predicted\"]\n",
    ").mean()\n",
    "\n",
    "within_one_accuracy_v2 = (\n",
    "    (valid_df_v2[\"actual\"] - valid_df_v2[\"predicted\"]).abs() <= 1\n",
    ").mean()\n",
    "\n",
    "exact_accuracy_v2, within_one_accuracy_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2b5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt V2 Exact Accuracy: nan%\n",
      "Prompt V2 ±1 Star Accuracy: nan%\n",
      "Prompt V2 JSON Validity Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt V2 Exact Accuracy: {exact_accuracy_v2:.2%}\")\n",
    "print(f\"Prompt V2 ±1 Star Accuracy: {within_one_accuracy_v2:.2%}\")\n",
    "print(f\"Prompt V2 JSON Validity Rate: {json_valid_rate_v2:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a749c",
   "metadata": {},
   "source": [
    "### Prompt Version 2 — Evaluation Results\n",
    "\n",
    "- Exact Match Accuracy (valid outputs only): **{exact_accuracy_v2:.2%}**\n",
    "- Within ±1 Star Accuracy (valid outputs only): **{within_one_accuracy_v2:.2%}**\n",
    "- JSON Validity Rate (overall): **{json_valid_rate_v2:.2%}**\n",
    "\n",
    "Compared to the baseline prompt, Prompt Version 2 demonstrates improved\n",
    "consistency due to explicit sentiment-to-rating rules. JSON validity\n",
    "also improves, indicating higher reliability in structured outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d624e",
   "metadata": {},
   "source": [
    "### Prompt Version 2 — Rule-Based Sentiment Mapping\n",
    "\n",
    "This prompt introduces explicit rules that map sentiment strength\n",
    "to discrete star ratings. By constraining the model’s interpretation\n",
    "of sentiment, ambiguity is reduced and predictions become more consistent.\n",
    "This is expected to improve exact-match accuracy compared to the baseline prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02880b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v3(review_text):\n",
    "    return f\"\"\"\n",
    "You are a rating prediction system.\n",
    "\n",
    "Follow these steps internally:\n",
    "1. Identify positive aspects in the review.\n",
    "2. Identify negative aspects in the review.\n",
    "3. Assess overall sentiment strength.\n",
    "4. Decide the most appropriate star rating (1–5).\n",
    "\n",
    "Do NOT reveal the steps.\n",
    "Return ONLY valid JSON.\n",
    "No markdown. No extra text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\n",
    "JSON output:\n",
    "{{\n",
    "  \"predicted_stars\": 1-5,\n",
    "  \"explanation\": \"brief reasoning\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4445093",
   "metadata": {},
   "source": [
    "### Prompt Version 3 — Structured Reasoning\n",
    "\n",
    "This prompt encourages the model to internally reason through\n",
    "positive and negative aspects of a review before predicting a rating.\n",
    "Although intermediate reasoning is hidden, this structured approach\n",
    "is expected to improve robustness on mixed-sentiment reviews and\n",
    "further increase prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa4ee8",
   "metadata": {},
   "source": [
    "Overall, performance differences are driven more by prompt structure\n",
    "than model capability. Rule-based and structured prompts improve\n",
    "consistency and reliability compared to the baseline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
